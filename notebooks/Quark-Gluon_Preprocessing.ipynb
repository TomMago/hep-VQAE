{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6360f2-8213-40e1-afb0-896d1d49f5ed",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook can be used to produce smaller versions of the Quark Gluon Dataset.\n",
    "I used it to produce the 12x12 and 40x40 ECAL datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a6f4a-538e-4e60-ae6f-be1615586aa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78501a2e-af16-4326-8b0c-3f1ef400ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 15:16:46.549029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-23 15:16:46.549046: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa4a2c-baf3-4cda-8f05-20d7d756b9b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1826c698-be86-42bd-8281-c681c569c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = h5py.File(\"../../data/quark-gluon/quark-gluon_train-set_n793900.hdf5\",\"r\")\n",
    "f2 = h5py.File(\"../../data/quark-gluon/quark-gluon_test-set_n139306.hdf5\",\"r\")\n",
    "f = h5py.File(\"../../data/quark-gluon/quark-gluon_test-set_n10000.hdf5\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e83dc-3145-4988-8caa-ec642996c35e",
   "metadata": {},
   "source": [
    "There are three files:\n",
    "- f3: ~800000 samples\n",
    "- f2: ~140000 samples\n",
    "- f: 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b42a496-8337-47a9-8170-05d61a7b703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f3.get('X_jets')\n",
    "y_train = f3.get('y')\n",
    "\n",
    "x_val = f2.get('X_jets')\n",
    "y_val = f2.get('y')\n",
    "\n",
    "x_test = f.get('X')\n",
    "y_test = f.get('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e31572-6aa5-4f5c-944b-8a5d7c62bf98",
   "metadata": {},
   "source": [
    "We will just name the dataset to reduce as `x_red`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f855550-36e3-4313-86c9-d82be6adb0fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_red \u001b[38;5;241m=\u001b[39m \u001b[43mf2\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_jets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m y_red \u001b[38;5;241m=\u001b[39m f2\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f2' is not defined"
     ]
    }
   ],
   "source": [
    "x_red = f2.get('X_jets')\n",
    "y_red = f2.get('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed444735-75ed-4988-8735-21b9bd998130",
   "metadata": {},
   "source": [
    "## resize and safe to new file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd2e60-f595-42c3-b548-8ada76373051",
   "metadata": {},
   "source": [
    "The different methods that can be used to reduce the dimension. \n",
    "Usually cropping first and then resizing should be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8521ff-e401-459d-8f20-9800423e9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(x, channel, crop_fraction):\n",
    "    return tf.image.central_crop(x[:,:,:,channel].reshape(x.shape[0],125,125,1), crop_fraction)\n",
    "\n",
    "def simple_resize(x, channel, scale, meth=\"bilinear\"):\n",
    "    return tf.image.resize(x[:,:,:,channel].reshape((x.shape[0],125,125,1)), (scale,scale), method=meth).numpy()\n",
    "\n",
    "def crop_and_resize(x, channel, scale, crop_fraction=0.8,meth=\"bilinear\"):\n",
    "    cropped = tf.image.central_crop(x[:,:,:,channel].reshape(x.shape[0],125,125,1), crop_fraction)\n",
    "    return tf.image.resize(cropped, (scale,scale), method=meth).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb383f7-fba7-4e6c-8a5a-721e018202fa",
   "metadata": {},
   "source": [
    "Fix some settings:\n",
    "\n",
    "- batch size: how many samples to load into memory at once\n",
    "- file name: name of output file\n",
    "- output shape: shape the rescale images should have\n",
    "- channel: which channel to use (in this case only ecal) - you could also rewrite to use all channels\n",
    "- crop fraction: To what percent to crop down before rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c092ea4-2b4e-47d3-b888-6cb40850e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_batches = x_red.shape[0] // batch_size\n",
    "events = num_batches * batch_size\n",
    "file_name = \"QG_rescaled\"\n",
    "channel = 1\n",
    "crop_fraction = 0.8\n",
    "\n",
    "output_shape = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103d54f-e7dc-43bb-950d-d89e2c7138ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  19642 / 39695\r"
     ]
    }
   ],
   "source": [
    "fnew = h5py.File(file_name, \"w\")\n",
    "\n",
    "dsetx = fnew.create_dataset(\"X\", (events,) + output_shape, dtype='f')\n",
    "dsety = fnew.create_dataset(\"y\", (events,), dtype='i')\n",
    "\n",
    "\n",
    "for i in range(int(num_batches)):\n",
    "    y = y_red[i * batch_size: (i + 1) * batch_size]\n",
    "    x = x_red[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "    x_small = crop_and_resize(x, channel, output_shape[0], crop_fraction=crop_fraction)\n",
    "    \n",
    "    div1 = np.max(x_small, axis=(1,2)).reshape((x.shape[0],1,1,1))\n",
    "    div1[div1 == 0] = 1\n",
    "    x_small = x_small / div1\n",
    "\n",
    "    dsety[i * batch_size: (i + 1) * batch_size] = y\n",
    "    dsetx[i * batch_size: (i + 1) * batch_size] = x.reshape((x_train_small.shape[0],)+output_shape)\n",
    "    print(\"batch \",i,\"/\",num_batches, end=\"\\r\")\n",
    "    \n",
    "fnew.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4dcf0d-cd6a-41d3-a0ca-3a61907c3549",
   "metadata": {},
   "source": [
    "### verify scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253a3c71-7ed4-4c53-b210-6259ee3d66bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'small_quark_gluon_12', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msmall_quark_gluon_12\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m x_s \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m y_s \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'small_quark_gluon_12', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "test = h5py.File(file_name,\"r\")\n",
    "\n",
    "x_s = test.get('X')\n",
    "y_s = test.get('y')\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].imshow(np.average(x_s[y_s[:]==0],0),norm=LogNorm(), cmap='binary')\n",
    "axs[0].title.set_text('Gluon')\n",
    "\n",
    "axs[1].imshow(np.average(x_s[y_s[:]==1],0),norm=LogNorm(), cmap='binary')\n",
    "axs[1].title.set_text('Quark')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
