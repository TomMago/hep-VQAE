{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6360f2-8213-40e1-afb0-896d1d49f5ed",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook can be used to produce smaller versions of the Quark Gluon Dataset.\n",
    "I used it to produce the 12x12 and 40x40 ECAL datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a6f4a-538e-4e60-ae6f-be1615586aa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78501a2e-af16-4326-8b0c-3f1ef400ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 16:56:24.194424: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-23 16:56:24.194465: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa4a2c-baf3-4cda-8f05-20d7d756b9b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1826c698-be86-42bd-8281-c681c569c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = h5py.File(\"../data/quark-gluon/quark-gluon_train-set_n793900.hdf5\",\"r\")\n",
    "f2 = h5py.File(\"../data/quark-gluon/quark-gluon_test-set_n139306.hdf5\",\"r\")\n",
    "f = h5py.File(\"../data/quark-gluon/quark-gluon_test-set_n10000.hdf5\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e83dc-3145-4988-8caa-ec642996c35e",
   "metadata": {},
   "source": [
    "There are three files:\n",
    "- f3: ~800000 samples\n",
    "- f2: ~140000 samples\n",
    "- f: 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b42a496-8337-47a9-8170-05d61a7b703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f3.get('X_jets')\n",
    "y_train = f3.get('y')\n",
    "\n",
    "x_val = f2.get('X_jets')\n",
    "y_val = f2.get('y')\n",
    "\n",
    "x_test = f.get('X')\n",
    "y_test = f.get('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e31572-6aa5-4f5c-944b-8a5d7c62bf98",
   "metadata": {},
   "source": [
    "We will just name the dataset to reduce as `x_red`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f855550-36e3-4313-86c9-d82be6adb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red = f2.get('X_jets')\n",
    "y_red = f2.get('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed444735-75ed-4988-8735-21b9bd998130",
   "metadata": {},
   "source": [
    "## resize and safe to new file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd2e60-f595-42c3-b548-8ada76373051",
   "metadata": {},
   "source": [
    "The different methods that can be used to reduce the dimension. \n",
    "Usually cropping first and then resizing should be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8521ff-e401-459d-8f20-9800423e9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(x, channel, crop_fraction):\n",
    "    return tf.image.central_crop(x[:,:,:,channel].reshape(x.shape[0],125,125,1), crop_fraction)\n",
    "\n",
    "def simple_resize(x, channel, scale, meth=\"bilinear\"):\n",
    "    return tf.image.resize(x[:,:,:,channel].reshape((x.shape[0],125,125,1)), (scale,scale), method=meth).numpy()\n",
    "\n",
    "def crop_and_resize(x, channel, scale, crop_fraction=0.8,meth=\"bilinear\"):\n",
    "    cropped = tf.image.central_crop(x[:,:,:,channel].reshape(x.shape[0],125,125,1), crop_fraction)\n",
    "    return tf.image.resize(cropped, (scale,scale), method=meth).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb383f7-fba7-4e6c-8a5a-721e018202fa",
   "metadata": {},
   "source": [
    "Fix some settings:\n",
    "\n",
    "- batch size: how many samples to load into memory at once\n",
    "- file name: name of output file\n",
    "- output shape: shape the rescale images should have\n",
    "- channel: which channel to use (in this case only ecal) - you could also rewrite to use all channels\n",
    "- crop fraction: To what percent to crop down before rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c092ea4-2b4e-47d3-b888-6cb40850e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_batches = x_red.shape[0] // batch_size\n",
    "events = num_batches * batch_size\n",
    "file_name = \"QG_rescaled\"\n",
    "channel = 1\n",
    "crop_fraction = 0.8\n",
    "\n",
    "output_shape = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8103d54f-e7dc-43bb-950d-d89e2c7138ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 16:56:29.441982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-23 16:56:29.442026: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-23 16:56:29.442051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-09-23 16:56:29.442376: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  106 / 6965\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fnew = h5py.File(file_name, \"w\")\n",
    "\n",
    "dsetx = fnew.create_dataset(\"X\", (events,) + output_shape, dtype='f')\n",
    "dsety = fnew.create_dataset(\"y\", (events,), dtype='i')\n",
    "\n",
    "\n",
    "for i in range(int(num_batches)):\n",
    "    y = y_red[i * batch_size: (i + 1) * batch_size]\n",
    "    x = x_red[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "    x_small = crop_and_resize(x, channel, output_shape[0], crop_fraction=crop_fraction)\n",
    "    \n",
    "    div1 = np.max(x_small, axis=(1,2)).reshape((x.shape[0],1,1,1))\n",
    "    div1[div1 == 0] = 1\n",
    "    x_small = x_small / div1\n",
    "\n",
    "    dsety[i * batch_size: (i + 1) * batch_size] = y\n",
    "    dsetx[i * batch_size: (i + 1) * batch_size] = x_small.reshape((x_small.shape[0],)+output_shape)\n",
    "    print(\"batch \",i,\"/\",num_batches, end=\"\\r\")\n",
    "    \n",
    "fnew.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4dcf0d-cd6a-41d3-a0ca-3a61907c3549",
   "metadata": {},
   "source": [
    "### verify scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a3c71-7ed4-4c53-b210-6259ee3d66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = h5py.File(file_name,\"r\")\n",
    "\n",
    "x_s = test.get('X')\n",
    "y_s = test.get('y')\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].imshow(np.average(x_s[y_s[:]==0],0),norm=LogNorm(), cmap='binary')\n",
    "axs[0].title.set_text('Gluon')\n",
    "\n",
    "axs[1].imshow(np.average(x_s[y_s[:]==1],0),norm=LogNorm(), cmap='binary')\n",
    "axs[1].title.set_text('Quark')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
