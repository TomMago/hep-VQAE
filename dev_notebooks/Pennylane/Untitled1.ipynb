{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd8abe6-6a09-43e7-aaf5-b75e076389cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 14:33:48.873026: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-17 14:33:48.873068: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7358fbc0-8294-4121-95ac-09ffa2bdf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X = np.array([[1,1],[1.5,1.5], [2.5,2.5], [2,2], [3.5,3.5], [3,3],[4,4], [5,5], [6,6],[7,7],[8,8],[9,9]])\n",
    "X = X / 9\n",
    "y = X**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa148f3-dd78-4055-a9fc-3fd25db03c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "layers = 10\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    #print(inputs.shape)\n",
    "    #qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    for i, j in enumerate(inputs):\n",
    "        qml.RX(j, wires=i)\n",
    "    used = 0\n",
    "    for i in range(layers):\n",
    "        for j in range(n_qubits):\n",
    "            qml.RY(weights[used + j], wires = j)\n",
    "        used = used + n_qubits\n",
    "    #qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513b6c76-e52c-422c-a2e6-3097bcd4397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 6\n",
    "weight_shapes = {\"weights\": (layers*n_qubits,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c6efb9-95d1-4d1b-9550-2bf7ebe01900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 14:33:50.965110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-17 14:33:50.965155: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-17 14:33:50.965179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-08-17 14:33:50.965482: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0475bb2b-d1e6-4739-9f6b-358ec267c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(2,))\n",
    "clayer_1 = tf.keras.layers.Dense(2)\n",
    "clayer_2 = tf.keras.layers.Dense(2)\n",
    "bigd = tf.keras.layers.Dense(10)\n",
    "bigg = tf.keras.layers.Dense(10)\n",
    "model = tf.keras.models.Sequential([clayer_1, qlayer, bigd, bigg, clayer_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfc15f9-078b-4bb9-912b-d3719879011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(opt, loss=\"mse\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01804b0a-5f73-4ae9-bcb1-4551b80f9f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 215ms/step - loss: 0.5302 - mse: 0.5302\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 1s 183ms/step - loss: 0.4747 - mse: 0.4747\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 1s 189ms/step - loss: 0.4276 - mse: 0.4276\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.3874 - mse: 0.3874\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.3527 - mse: 0.3527\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.3232 - mse: 0.3232\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 1s 170ms/step - loss: 0.2748 - mse: 0.2748\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.2553 - mse: 0.2553\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 0.2383 - mse: 0.2383\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 1s 191ms/step - loss: 0.2233 - mse: 0.2233\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.2100 - mse: 0.2100\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 1s 200ms/step - loss: 0.1791 - mse: 0.1791\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 1s 191ms/step - loss: 0.1707 - mse: 0.1707\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 1s 171ms/step - loss: 0.1634 - mse: 0.1634\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.1570 - mse: 0.1570\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.1513 - mse: 0.1513\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.1462 - mse: 0.1462\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 0.1418 - mse: 0.1418\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 1s 182ms/step - loss: 0.1376 - mse: 0.1376\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.1340 - mse: 0.1340\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.1306 - mse: 0.1306\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.1276 - mse: 0.1276\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 1s 176ms/step - loss: 0.1249 - mse: 0.1249\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.1227 - mse: 0.1227\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.1204 - mse: 0.1204\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 0.1184 - mse: 0.1184\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 1s 179ms/step - loss: 0.1167 - mse: 0.1167\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 0.1151 - mse: 0.1151\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 1s 180ms/step - loss: 0.1137 - mse: 0.1137\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 1s 178ms/step - loss: 0.1125 - mse: 0.1125\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 0.1112 - mse: 0.1112\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 1s 176ms/step - loss: 0.1103 - mse: 0.1103\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 0.1092 - mse: 0.1092\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.1084 - mse: 0.1084\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 1s 192ms/step - loss: 0.1078 - mse: 0.1078\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.1069 - mse: 0.1069\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 1s 189ms/step - loss: 0.1063 - mse: 0.1063\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 0.1058 - mse: 0.1058\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 1s 181ms/step - loss: 0.1053 - mse: 0.1053\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 1s 168ms/step - loss: 0.1047 - mse: 0.1047\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 1s 174ms/step - loss: 0.1044 - mse: 0.1044\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 1s 218ms/step - loss: 0.1038 - mse: 0.1038\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 1s 183ms/step - loss: 0.1036 - mse: 0.1036\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 1s 179ms/step - loss: 0.1033 - mse: 0.1033\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 0.1029 - mse: 0.1029\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 1s 182ms/step - loss: 0.1025 - mse: 0.1025\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.1023 - mse: 0.1023\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.1022 - mse: 0.1022\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.1019 - mse: 0.1019\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.1016 - mse: 0.1016\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 1s 189ms/step - loss: 0.1017 - mse: 0.1017\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 1s 179ms/step - loss: 0.1014 - mse: 0.1014\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 1s 192ms/step - loss: 0.1011 - mse: 0.1011\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 1s 184ms/step - loss: 0.1010 - mse: 0.1010\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.1011 - mse: 0.1011\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 1s 181ms/step - loss: 0.1007 - mse: 0.1007\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.1007 - mse: 0.1007\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 1s 183ms/step - loss: 0.1005 - mse: 0.1005\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.1003 - mse: 0.1003\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 0.1004 - mse: 0.1004\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 1s 191ms/step - loss: 0.1002 - mse: 0.1002\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 0.1004 - mse: 0.1004\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.1003 - mse: 0.1003\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 0.1000 - mse: 0.1000\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 1s 192ms/step - loss: 0.1002 - mse: 0.1002\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.0999 - mse: 0.0999\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 1s 189ms/step - loss: 0.0999 - mse: 0.0999\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 1s 191ms/step - loss: 0.0999 - mse: 0.0999\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 1s 209ms/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 1s 230ms/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.1000 - mse: 0.1000\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 1s 245ms/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 2s 291ms/step - loss: 0.0997 - mse: 0.0997\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 1s 224ms/step - loss: 0.0997 - mse: 0.0997\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 2s 250ms/step - loss: 0.0997 - mse: 0.0997\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 1s 237ms/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 1s 241ms/step - loss: 0.0995 - mse: 0.0995\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 1s 248ms/step - loss: 0.0996 - mse: 0.0996\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 2s 285ms/step - loss: 0.0997 - mse: 0.0997\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 0.0997 - mse: 0.0997\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 1s 204ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 1s 207ms/step - loss: 0.0995 - mse: 0.0995\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.0995 - mse: 0.0995\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.0995 - mse: 0.0995\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 1s 240ms/step - loss: 0.0995 - mse: 0.0995\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 1s 187ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 1s 214ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 1s 176ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.0993 - mse: 0.0993\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 1s 206ms/step - loss: 0.0996 - mse: 0.0996\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 1s 183ms/step - loss: 0.0993 - mse: 0.0993\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 0.0993 - mse: 0.0993\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.0994 - mse: 0.0994\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.0994 - mse: 0.0994\n"
     ]
    }
   ],
   "source": [
    "fitting = model.fit(X, y, epochs=100, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1621fe-deca-4516-92a8-fbca7da812e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30589446, 0.3043422 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0.5,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ccd172c-f4e9-4837-b41b-ec4441ae535a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30589446, 0.3043422 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0.1,0.1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
