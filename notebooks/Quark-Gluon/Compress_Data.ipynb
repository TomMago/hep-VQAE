{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78501a2e-af16-4326-8b0c-3f1ef400ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 00:17:38.707332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 00:17:38.707351: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-07-08 00:17:39.700887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-08 00:17:39.700908: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-08 00:17:39.700923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-07-08 00:17:39.701137: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "from hep_VQAE import data_preprocessing as dp\n",
    "from hep_VQAE import CAE as cae\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1826c698-be86-42bd-8281-c681c569c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"data/quark-gluon/quark-gluon_train-set_n793900.hdf5\",\"r\")\n",
    "f2 = h5py.File(\"data/quark-gluon/quark-gluon_test-set_n10000.hdf5\",\"r\")\n",
    "#f3 = h5py.File(\"data/quark-gluon/quark-gluon_test-set_n139306.hdf5\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b42a496-8337-47a9-8170-05d61a7b703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f.get('X_jets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806f8495-db63-4eeb-9e19-f7a441a45cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = f.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f738b550-54eb-490d-9259-409598700ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"X_jets\": shape (793900, 125, 125, 3), type \"<f4\">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0340cb97-b4c9-48be-8f87-f2aab9236339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793900, 125, 125, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e61f5df-e390-4256-bdb1-92e999f6822c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "793900 // 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c97b5ae-8071-4e33-ac66-8a938c29ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ddc5aad-0988-45ff-8b03-dd879e262767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Sequence) :\n",
    "  \n",
    "  def __init__(self, hdf5_file, batch_size) :\n",
    "    self.hdf5_file = hdf5_file\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  # Länge der Trainingsdaten (Anzahl der Batches)\n",
    "  def __len__(self) :\n",
    "    return x_train.shape[0]//self.batch_size\n",
    "  \n",
    "  # Lädt Bilder anhand der Pfade aus dem Trainingsarray\n",
    "  def __getitem__(self, idx) :\n",
    "    \n",
    "    return self.hdf5_file[idx * self.batch_size: (idx + 1) * self.batch_size], self.hdf5_file[idx * self.batch_size: (idx + 1) * self.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d42d08d-c762-4427-8779-c061bc702bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = Generator(x_train, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2934adb-386d-4556-9b49-61df0a75f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cae.Convolutional_Autoencoder2(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ff7752-42f4-4a76-a77f-c4c19db3e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 42, 42, 8)         224       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 9606      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,134\n",
      "Trainable params: 34,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5403bb80-136e-49f3-8653-2c17c84a2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739e2947-7f29-4fc3-a714-ec288fb1218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_314042/565034597.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(traingen,epochs=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "882/882 [==============================] - 4956s 6s/step - loss: 0.0012\n",
      "Epoch 2/2\n",
      "882/882 [==============================] - 5067s 6s/step - loss: 2.1277e-04\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(traingen,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795dfb26-4241-4ccf-8cb3-25e861077450",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = f2.get('X')\n",
    "y_test = f2.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40090f20-2528-42ca-a694-705097545f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 125, 125, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2cbd300-e755-4513-8ada-248a38ea12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(x):\n",
    "    pred = model.predict(x)\n",
    "    return np.mean(np.abs(x - pred)**2,axis=(1,2,3))\n",
    "\n",
    "def recon_acc(x):\n",
    "    return 1 - mae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f226136c-a5bd-4b9d-930f-1d150f262076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 125, 125, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:2000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c4b893f-1a5c-4add-bddb-18175b03748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 125, 125, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[8000:10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9069c887-4381-4f61-8fc9-6f2aaccfd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerrooo = recon_acc(x_test[:2000])\n",
    "one = recon_acc(x_test[8000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93305172-b2ec-41b4-ac51-8ea7bb413edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerrooo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064fd10-78d6-4e4b-bef9-379e1be7b733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46674d8-8e63-46f6-ad67-c74ed5122358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999977\n",
      "0.99999565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f94385b5400>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.median(zerrooo))\n",
    "bins = np.histogram(np.hstack((zerrooo, one)), bins=150)[1]\n",
    "plt.hist(zerrooo, histtype='step', label=\"sixes\",bins=bins)#,bins=[0.0004,0.0005,0.0006,0.0007,0.0008,0.0009,0.001,0.0011,0.0012,0.0013])\n",
    "print(np.median(one))\n",
    "plt.hist(one, histtype='step', label=\"threes\",bins=bins)#,bins=[0.0004,0.0005,0.0006,0.0007,0.0008,0.0009,0.001,0.0011,0.0012,0.0013])\n",
    "plt.xlabel(\"Reconstruction error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d791b25-e194-4b04-835c-8db22badad01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793900"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ade2300-cb30-452c-bd9e-a5c5b289aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a6cc057-15cb-4765-aa64-c13556e7fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = x_train.shape[0]/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be3006a2-5955-4bd3-b50d-6876358dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsmall.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "450de7e8-9e0b-4216-a99f-6909edaa3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\r"
     ]
    }
   ],
   "source": [
    "fsmall = h5py.File('../../data/compressed2.hdf5','w')\n",
    "fsmall.create_dataset('X', shape=(x_train.shape[0],6))\n",
    "fsmall.create_dataset('y', shape=(x_train.shape[0], 1))\n",
    "\n",
    "for i in range(int(num_batches)):\n",
    "    fsmall['X'][i * batch_size: (i + 1) * batch_size] = model.encoder(x_train[i * batch_size: (i + 1) * batch_size])\n",
    "    fsmall['y'][i * batch_size: (i + 1) * batch_size] = y_train[i * batch_size: (i + 1) * batch_size].reshape((batch_size,1))\n",
    "    print(i, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e1fe0c9-0a06-4c93-ba47-0fa889c14c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1600)              11200     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 15, 15, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 31, 31, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 62, 62, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 125, 125, 8)      1160      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 125, 125, 3)       99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,475\n",
      "Trainable params: 72,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f712f9-9aa2-41a1-8cf7-8db05a635e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fa340be-7ad2-42ab-b567-02ca0b9fdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2828ada-8bde-4342-82cb-7e8a07b18cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Input(shape=(6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14e459b0-bd7a-4f87-909d-0c883ced1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "    layers.Input(shape=(6,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec073e8e-4d66-4760-8201-083b2d04033c",
   "metadata": {},
   "source": [
    "## from tensorflow.keras.models import Model\n",
    "newmodel = Model(inputs=x, outputs=model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "192b8e8f-51e7-40da-9ee7-071605c44fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_inferred_value',\n",
       " '_keras_history',\n",
       " '_name',\n",
       " '_overload_all_operators',\n",
       " '_overload_operator',\n",
       " '_to_placeholder',\n",
       " '_type_spec',\n",
       " 'dtype',\n",
       " 'experimental_ref',\n",
       " 'from_tensor',\n",
       " 'from_type_spec',\n",
       " 'get_shape',\n",
       " 'is_tensor_like',\n",
       " 'name',\n",
       " 'node',\n",
       " 'op',\n",
       " 'ref',\n",
       " 'set_shape',\n",
       " 'shape',\n",
       " 'type_spec']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a65130b-6fd4-48e9-9fe2-75d6cba2bb3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_1\" (type Sequential).\n\nInput 0 of layer \"dense_1\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (6,)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(6,), dtype=int64)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py:228\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    227\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    232\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n\nInput 0 of layer \"dense_1\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (6,)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(6,), dtype=int64)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "model.decoder(np.array([1,1,1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb7fbc-48f1-40e0-8a84-61774c8f501e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
