{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17aa9b0-2979-42ab-bd79-5ce108a99efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 17:06:39.514370: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-12 17:06:39.514391: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hep_VQAE import data_preprocessing as dp\n",
    "import tensorflow as tf\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32774da5-84e7-4b6a-8765-63f24714a067",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7586f1e-55d4-45a2-b014-394bd7b70c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_QBITS = 4\n",
    "LATENT_QBITS = 2\n",
    "TRASH_QBITS = DATA_QBITS - LATENT_QBITS\n",
    "TOTAL_QBITS = DATA_QBITS + TRASH_QBITS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95725cf-c819-49c1-952f-5034af4a33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = qml.device('qiskit.ibmq', wires=TOTAL_QBITS, backend='ibmq_qasm_simulator', ibmqx_token=\"b3d3c72c5444443a55aad7cb536d64eb91922e050d1d9f4180c86c73326a601ab32b433e1c57ff26c94e011018435962f5ed3b49c3f6918fb6cb0adfd1a89f72\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4207c76d-b3c1-45a3-897d-d2022f079f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(params, data, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.RY(params[i*2] + params[i*2+1]*data[i] , wires=i)\n",
    "    qml.CNOT(wires=[wires[-1],0])\n",
    "    for i in range(len(wires)-1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "\n",
    "@qml.batch_input(argnum=0)\n",
    "@qml.qnode(dev1)\n",
    "def circuit(data, enc_params):\n",
    "    #qml.AngleEmbedding(data, wires=range(DATA_QBITS))\n",
    "    print(\"d\")\n",
    "    print(data)\n",
    "    print(\"pr\")\n",
    "    print(enc_params)\n",
    "    for i in range(LAYERS):\n",
    "        for j in range(DATA_QBITS):\n",
    "            qml.RY(enc_params[i*2*DATA_QBITS:(i+1)*2*DATA_QBITS][j*2] + enc_params[i*2*DATA_QBITS:(i+1)*2*DATA_QBITS][j*2+1]*data[j] , wires=j)\n",
    "        qml.CNOT(wires=[DATA_QBITS-1,0])\n",
    "        for i in range(DATA_QBITS-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "        #layer(enc_params[i*2*DATA_QBITS:(i+1)*2*DATA_QBITS], data, [x for x in range(DATA_QBITS)])\n",
    "    qml.Hadamard(wires=TOTAL_QBITS-1)\n",
    "    for i in range(TRASH_QBITS):\n",
    "        #c += cirq.ControlledGate(sub_gate=cirq.SWAP, num_controls=1).on(swap_qbit, reference_qbits[i], network_qbits[num_data_qbits - num_latent_qbits:][i])\n",
    "        qml.CSWAP(wires=[TOTAL_QBITS - 1, LATENT_QBITS + i, DATA_QBITS + i])\n",
    "    qml.Hadamard(wires=TOTAL_QBITS-1)\n",
    "    return qml.expval(qml.PauliZ(TOTAL_QBITS-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fedda7f2-e929-467d-91d9-2052f4c317b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = qml.draw_mpl(circuit)([1,11,1,1,1,1,1,1,1,1,1,1],[0.1,0.24,0.3,0.14])\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0b6090-2adb-4587-b744-c14daca04f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65a4c32-2de0-4a75-84f9-f4bd0645c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_36(x, y):\n",
    "    keep = (y == 3) | (y == 6)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 3\n",
    "    return x,y\n",
    "\n",
    "x_train, y_train = filter_36(x_train, y_train)\n",
    "x_test, y_test = filter_36(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8eb04c5-1a6f-451e-8dea-b4da3650f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSCALE = 2\n",
    "DATA_DIMENSION = DOWNSCALE*DOWNSCALE\n",
    "LATENT_BITS = 2\n",
    "\n",
    "x_train, x_test = dp.PCA_reduce(x_train, DATA_DIMENSION, val_data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95eecacd-755d-4355-826c-c5ebd7e90260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_threes = np.array(x_train[y_train==True])\n",
    "x_train = np.array(x_train[y_train==False])\n",
    "\n",
    "x_test_threes = np.array(x_test[y_test==True])\n",
    "x_test = np.array(x_test[y_test==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae511ff-2c31-4175-b48d-c31c71515d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = 1\n",
    "\n",
    "def cost(params, X):\n",
    "    loss = 0.0\n",
    "    for i in range(len(X)):\n",
    "        f = circuit(params, X[i])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(X)\n",
    "\n",
    "def cost_batch(params, X):\n",
    "    loss = 0.0\n",
    "    batch_res = circuit(params, X)\n",
    "    print(type(batch_res))\n",
    "    print(\"--\")\n",
    "    print(batch_res)\n",
    "    loss = np.mean((1-batch_res)**2)\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372c05ea-5235-4232-a3f3-fadca2c1bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size):\n",
    "    for start_idx in range(0, data.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield data[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a01d4b1-3afd-45ed-a5b5-f6ef6ac8f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 1\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d2a03ed-55c1-49ad-82d3-770e912da9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "# opt = qml.QNGOptimizer(learning_rate)\n",
    "#opt = GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "646980f1-8197-4a2b-9f00-b8e5f7da810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_shapes = {\"weights\": (LAYERS*2*DATA_QBITS)}\n",
    "params = np.random.uniform(size=weight_shapes[\"weights\"], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78627196-5a49-4ba4-a2a6-99aae66c8631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4252d-4a6c-4ecc-99b9-cce49b359ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b660710-5ced-49ba-b15a-f3a1504a4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:50]\n",
    "x_train_threes = x_train_threes[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cabaaa49-50a0-4f65-81a0-0cd250bfb5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_params\n",
      "[0.27785436 0.02686934 0.1945819  0.8669702  0.89783929 0.48320459\n",
      " 0.12408604 0.10524092]\n",
      "d\n",
      "Autograd ArrayBox with value [0.27785436 0.02686934 0.1945819  0.8669702  0.89783929 0.48320459\n",
      " 0.12408604 0.10524092]\n",
      "pr\n",
      "[[0.79680565 0.45641394 0.59183778 0.44915419]\n",
      " [0.52812885 0.37485367 0.31909504 0.52948142]\n",
      " [0.69171564 0.45219032 0.34722902 0.491524  ]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_params\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n\u001b[0;32m----> 8\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(j, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:88\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     g, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# unwrap from list if one argument, cleaner return\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 117\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/_grad.py:115\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[0;32m--> 115\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/_grad.py:133\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grad_with_forward\u001b[39m(fun, x):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124;03m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    value.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/autograd/core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[1;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[0;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/autograd/tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[0;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/autograd/wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mcost_batch\u001b[0;34m(params, X)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost_batch\u001b[39m(params, X):\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m     batch_res \u001b[38;5;241m=\u001b[39m \u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(batch_res))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/transforms/batch_transform.py:288\u001b[0m, in \u001b[0;36mbatch_transform.default_qnode_wrapper.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    287\u001b[0m     shots \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 288\u001b[0m     \u001b[43mqnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     tapes, processing_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct(qnode\u001b[38;5;241m.\u001b[39mqtape, \u001b[38;5;241m*\u001b[39mtargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtkwargs)\n\u001b[1;32m    291\u001b[0m     interface \u001b[38;5;241m=\u001b[39m qnode\u001b[38;5;241m.\u001b[39minterface\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/qnode.py:526\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mQuantumTape()\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output\n\u001b[1;32m    529\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mcircuit\u001b[0;34m(data, enc_params)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(LAYERS):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(DATA_QBITS):\n\u001b[0;32m---> 19\u001b[0m         qml\u001b[38;5;241m.\u001b[39mRY(enc_params[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mDATA_QBITS:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mDATA_QBITS][j\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43menc_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mDATA_QBITS\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mDATA_QBITS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m*\u001b[39mdata[j] , wires\u001b[38;5;241m=\u001b[39mj)\n\u001b[1;32m     20\u001b[0m     qml\u001b[38;5;241m.\u001b[39mCNOT(wires\u001b[38;5;241m=\u001b[39m[DATA_QBITS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(DATA_QBITS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/pennylane/numpy/tensor.py:184\u001b[0m, in \u001b[0;36mtensor.__getitem__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 184\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, tensor):\n\u001b[1;32m    187\u001b[0m         item \u001b[38;5;241m=\u001b[39m tensor(item, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for it in range(epochs):\n",
    "    for j,Xbatch in enumerate(iterate_minibatches(x_train, batch_size=batch_size)):\n",
    "        Xbatch = np.array(Xbatch, requires_grad=False)\n",
    "        print(\"init_params\")\n",
    "        print(params)\n",
    "        params = opt.step(cost_batch, params, Xbatch)\n",
    "        print(j, end=\"\\r\")\n",
    "        break\n",
    "    break\n",
    "    loss = cost(params, x_train)\n",
    "    val_loss = cost(params, x_test[:100])\n",
    "    \n",
    "    print(f\"Epoch: {it} | Loss: {loss} | Val Loss: {val_loss}\")\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time for {epochs} epochs with {LAYERS} layers: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7b71d-a5bc-46d0-9320-2d0e2eb5ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_threes = x_test_threes[:100]\n",
    "x_test = x_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f3d7b-1d4a-4c6a-a0aa-b41885a5310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_six = np.array([circuit(params,i) for i in x_test])\n",
    "np.mean(pred_six)\n",
    "print(\"Median six reconstruciton fidelities: \",np.median(pred_six))\n",
    "\n",
    "pred_three = np.array([circuit(params,i) for i in x_test_threes])\n",
    "np.mean(pred_three)\n",
    "print(\"Median three reconstruciton fidelities: \",np.median(pred_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc3a26-6089-49f6-94d0-c87484628ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.histogram(np.hstack((pred_six.reshape((pred_six.shape[0],)), pred_three.reshape((pred_three.shape[0],)))), bins=10)[1]\n",
    "plt.hist(pred_six, histtype='step', label=\"sixes\",bins=bins)\n",
    "plt.hist(pred_three, histtype='step', label=\"threes\",bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a3544-699e-485e-ba8d-0a53de028ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_for_threshold(T):\n",
    "    # sixes that are predicted six\n",
    "    num_six_right = np.sum(pred_six > T)\n",
    "    # threes that are predicted three\n",
    "    num_three_right = np.sum(pred_three < T)\n",
    "    acc = (num_six_right + num_three_right)/(len(pred_six) + len(pred_three))\n",
    "    return acc\n",
    "\n",
    "Ts = np.linspace(0,1,2000)\n",
    "accs = []\n",
    "for i in Ts:\n",
    "    accs.append(acc_for_threshold(i))\n",
    "print(max(accs))\n",
    "plt.ylabel(\"Tagging accuracy\")\n",
    "plt.xlabel(\"Anomaly threshold\")\n",
    "plt.plot(Ts, accs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268628bc-9a71-401e-8c93-01cd99d29657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
