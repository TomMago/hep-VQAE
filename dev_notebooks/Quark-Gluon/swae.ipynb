{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Notebook for SWAE on the MNIST Dataset\n",
    "\n",
    "This notebook implements Sliced Wasserstein Auto-Encoders (SWAE).\n",
    "\n",
    "To run this notebook you'll require the following packages:\n",
    "\n",
    "* Numpy\n",
    "* Matplotlib\n",
    "* tensorflow\n",
    "* Keras\n",
    "* h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 15:40:50.919614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-12 15:40:50.919646: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/tom/.conda/envs/tfq/lib/python3.9/site-packages/cirq/ops/gateset.py:376: UserWarning: v0.14.1 is the last release `cirq.GlobalPhaseGate` is included by default. If you were relying on this behavior, you can include a `cirq.GlobalPhaseGate` in your `*gates`. If not, then you can ignore this warning. It will be removed in v0.16\n",
      "  warnings.warn(\n",
      "2022-08-12 15:40:53.148552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-12 15:40:53.148575: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-12 15:40:53.148589: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-08-12 15:40:53.148782: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.utils\n",
    "from keras.layers import Input,Dense, Flatten\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, UpSampling2D, AveragePooling2D\n",
    "from keras.layers import LeakyReLU,Reshape\n",
    "from keras.datasets import mnist\n",
    "from keras.models import save_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "from hep_VQAE import data_preprocessing as dp\n",
    "from hep_VQAE import CAE as cae\n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from hep_VQAE import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define three helper functions\n",
    " * generateTheta(L,dim) -> Generates $L$ random sampels from $\\mathbb{S}^{dim-1}$\n",
    " * generateZ(batchsize,endim) -> Generates 'batchsize' samples 'endim' dimensional samples from $q_Z$ \n",
    " * stitchImages(I,axis=0) -> Helps us with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTheta(L,endim):\n",
    "    # This function generates L random samples from the unit `ndim'-u\n",
    "    theta=[w/np.sqrt((w**2).sum()) for w in np.random.normal(size=(L,endim))]\n",
    "    return np.asarray(theta)\n",
    "def generateZ(batchsize, endim):\n",
    "    # This function generates 2D samples from a `circle' distribution in \n",
    "    # a 2-dimensional space\n",
    "    #r=np.random.uniform(size=(batchsize))\n",
    "    #theta=2*np.pi*np.random.uniform(size=(batchsize))\n",
    "    #x=r*np.cos(theta)\n",
    "    #y=r*np.sin(theta)\n",
    "    #z_=np.array([x,y]).T\n",
    "    return np.random.uniform(size=(batchsize,endim))\n",
    "def stitchImages(I,axis=0):\n",
    "    n,N,M,K=I.shape\n",
    "    if axis==0:\n",
    "        img=np.zeros((N*n,M,K))\n",
    "        for i in range(n):\n",
    "            img[i*N:(i+1)*N,:,:]=I[i,:,:,:]\n",
    "    else:\n",
    "        img=np.zeros((N,M*n,K))\n",
    "        for i in range(n):\n",
    "            img[:,i*M:(i+1)*M,:]=I[i,:,:,:]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Encoder/Decoder as Keras graphs\n",
    "\n",
    "In this section we define our encoder-decoder architectures and the corresponding loss function for the SWAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Input((40,40,1)) #Input image \n",
    "interdim=128 # This is the dimension of intermediate latent variable \n",
    "             #(after convolution and before embedding)\n",
    "endim=30 # Dimension of the embedding space\n",
    "embedd=Input((endim,)) #Keras input to Decoder\n",
    "depth=16 # This is a design parameter and in fact it is not the depth!\n",
    "L=50 # Number of random projections\n",
    "batchsize=500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 40, 40, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 40, 40, 16)        160       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 40, 40, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 16)        2320      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 40, 40, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 20, 20, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 32)        4640      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 32)        9248      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 10, 10, 32)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 5, 5, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                3870      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,590\n",
      "Trainable params: 280,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=Conv2D(depth*1, (3, 3), padding='same')(img)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Conv2D(depth*1, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=AveragePooling2D((2, 2), padding='same')(x)\n",
    "x=Conv2D(depth*2, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Conv2D(depth*2, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=AveragePooling2D((2, 2), padding='same')(x)\n",
    "x=Conv2D(depth*4, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Conv2D(depth*4, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=AveragePooling2D((2, 2), padding='same')(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(interdim,activation='relu')(x)\n",
    "encoded=Dense(endim)(x)\n",
    "\n",
    "encoder=Model(inputs=[img],outputs=[encoded])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3968      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1600)              206400    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 10, 10, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 20, 20, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 20, 20, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 20, 20, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 20, 20, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 40, 40, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 40, 40, 32)        18464     \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 40, 40, 32)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 40, 40, 32)        9248      \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 40, 40, 32)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 40, 40, 1)         289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 386,081\n",
      "Trainable params: 386,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=Dense(interdim)(embedd)\n",
    "x=Dense(depth*100,activation='relu')(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Reshape((5,5,4*depth))(x)\n",
    "x=UpSampling2D((2, 2))(x)\n",
    "x=Conv2D(depth*4, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Conv2D(depth*4, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=UpSampling2D((2, 2))(x)\n",
    "x=Conv2D(depth*4, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Conv2D(depth*4, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=UpSampling2D((2, 2))(x)\n",
    "x=Conv2D(depth*2, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "x=Conv2D(depth*2, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "# x=BatchNormalization(momentum=0.8)(x)\n",
    "decoded=Conv2D(1, (3, 3), padding='same',activation='sigmoid')(x)\n",
    "\n",
    "decoder=Model(inputs=[embedd],outputs=[decoded])\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define Keras variables for $\\theta$ and sample $z$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=K.variable(generateTheta(L,endim)) #Define a Keras Variable for \\theta_ls\n",
    "z=K.variable(generateZ(batchsize,endim)) #Define a Keras Variable for samples of z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put encoder and decoder together to get the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 40, 40, 1)]       0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 30)                280590    \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 40, 40, 1)         386081    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 666,671\n",
      "Trainable params: 666,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generate the autoencoder by combining encoder and decoder\n",
    "aencoded=encoder(img)\n",
    "ae=decoder(aencoded)\n",
    "autoencoder=Model(inputs=[img],outputs=[ae])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [30,500], In[1]: [30,50] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m projae\u001b[38;5;241m=\u001b[39mK\u001b[38;5;241m.\u001b[39mdot(aencoded,K\u001b[38;5;241m.\u001b[39mtranspose(theta))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Let projz be the projection of the $q_Z$ samples\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m projz\u001b[38;5;241m=\u001b[39m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate the Sliced Wasserstein distance by sorting \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# the projections and calculating the L2 distance between\u001b[39;00m\n\u001b[1;32m      7\u001b[0m W2\u001b[38;5;241m=\u001b[39m(tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mtop_k(tf\u001b[38;5;241m.\u001b[39mtranspose(projae),k\u001b[38;5;241m=\u001b[39mbatchsize)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m-\u001b[39m\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mtop_k(tf\u001b[38;5;241m.\u001b[39mtranspose(projz),k\u001b[38;5;241m=\u001b[39mbatchsize)\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tfq/lib/python3.9/site-packages/keras/backend.py:2223\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   2221\u001b[0m   out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39msparse_dense_matmul(x, y)\n\u001b[1;32m   2222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2223\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [30,500], In[1]: [30,50] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "# Let projae be the projection of the encoded samples\n",
    "projae=K.dot(aencoded,K.transpose(theta))\n",
    "# Let projz be the projection of the $q_Z$ samples\n",
    "projz=K.dot(z,K.transpose(theta))\n",
    "# Calculate the Sliced Wasserstein distance by sorting \n",
    "# the projections and calculating the L2 distance between\n",
    "W2=(tf.nn.top_k(tf.transpose(projae),k=batchsize).values-\n",
    "    tf.nn.top_k(tf.transpose(projz),k=batchsize).values)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2weight=K.variable(10.0)\n",
    "crossEntropyLoss= (1.0)*K.mean(K.binary_crossentropy(K.flatten(img),K.flatten(ae)))\n",
    "L1Loss= (1.0)*K.mean(K.abs(K.flatten(img)-K.flatten(ae)))\n",
    "W2Loss= w2weight*K.mean(W2)\n",
    "# I have a combination of L1 and Cross-Entropy loss for the first term and then \n",
    "# W2 for the second term\n",
    "vae_Loss=L1Loss+crossEntropyLoss+W2Loss\n",
    "#autoencoder.add_loss(vae_Loss) # Add the custom loss to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "autoencoder.compile(optimizer='rmsprop',loss=vae_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"small_quark_gluon_candr\",\"r\")\n",
    "x_train = f.get('X')\n",
    "y_train = f.get('y')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train[:], y_train[:], test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ones = x_train[y_train==1]\n",
    "x_train_ones = x_train_ones.reshape(x_train_ones.shape + (1,))\n",
    "x_train = x_train[y_train==0]\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "\n",
    "div1 = np.max(x_train, axis=(1,2)).reshape((x_train.shape[0],1,1,1))\n",
    "div1[div1 == 0] = 1\n",
    "x_train = x_train / div1\n",
    "div2 = np.max(x_train_ones, axis=(1,2)).reshape((x_train_ones.shape[0],1,1,1))\n",
    "div2[div2 == 0] = 1\n",
    "x_train_ones = x_train_ones / div2\n",
    "\n",
    "x_val_ones = x_val[y_val==1]\n",
    "x_val_ones = x_val_ones.reshape(x_val_ones.shape + (1,))\n",
    "x_val = x_val[y_val==0]\n",
    "x_val = x_val.reshape(x_val.shape + (1,))\n",
    "\n",
    "div1 = np.max(x_val, axis=(1,2)).reshape((x_val.shape[0],1,1,1))\n",
    "div1[div1 == 0] = 1\n",
    "x_val = x_val / div1\n",
    "div2 = np.max(x_val_ones, axis=(1,2)).reshape((x_val_ones.shape[0],1,1,1))\n",
    "div2[div2 == 0] = 1\n",
    "x_val_ones = x_val_ones / div2\n",
    "\n",
    "\n",
    "x_test = x_val\n",
    "x_test_ones = x_val_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=[]\n",
    "fig1=plt.figure()\n",
    "for epoch in range(30):\n",
    "    ind=np.random.permutation(x_train.shape[0])    \n",
    "    if epoch>10:\n",
    "        K.set_value(w2weight,1.1*K.eval(w2weight))\n",
    "    for i in range(int(x_train.shape[0]/batchsize)):\n",
    "        Xtr=x_train[ind[i*batchsize:(i+1)*batchsize],...]\n",
    "        theta_=generateTheta(L,endim)\n",
    "        z_=generateZ(batchsize,endim)\n",
    "        K.set_value(z,z_)\n",
    "        K.set_value(theta,theta_)        \n",
    "        loss.append(autoencoder.train_on_batch(x=Xtr,y=None))        \n",
    "    plt.plot(np.asarray(loss))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf()) \n",
    "    time.sleep(1e-3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and decode x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test autoencoder\n",
    "en=encoder.predict(x_train)# Encode the images\n",
    "dec=decoder.predict(en) # Decode the encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the encoding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the encoded samples\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(en[:,0],-en[:,1],c=10*y_train, cmap=plt.cm.Spectral)\n",
    "plt.xlim([-1.5,1.5])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a grid in the encoding space and decode it to visualize this space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample the latent variable on a Nsample x Nsample grid\n",
    "Nsample=25\n",
    "hiddenv=np.meshgrid(np.linspace(-1,1,Nsample),np.linspace(-1,1,Nsample))\n",
    "v=np.concatenate((np.expand_dims(hiddenv[0].flatten(),1),\n",
    "                  np.expand_dims(hiddenv[1].flatten(),1)),1)\n",
    "# Decode the grid\n",
    "decodeimg=np.squeeze(decoder.predict(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the grid \n",
    "count=0\n",
    "img=np.zeros((Nsample*28,Nsample*28))\n",
    "for i in range(Nsample):\n",
    "    for j in range(Nsample):        \n",
    "        img[i*28:(i+1)*28,j*28:(j+1)*28]=decodeimg[count,...]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the z samples\n",
    "plt.figure(figsize=(10,10))\n",
    "Z=generateZ(10000)\n",
    "plt.scatter(Z[:,0],Z[:,1])\n",
    "plt.xlim([-1.5,1.5])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(encoder,filepath='MNIST_circle_encoder.h5')\n",
    "save_model(decoder,filepath='MNIST_circle_decoder.h5')\n",
    "save_model(autoencoder,filepath='MNIST_circle_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random samples with respect to $q_Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomSamples=generateZ(Nsample**2)\n",
    "randomdecodeimg=np.squeeze(decoder.predict(randomSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgRandom=np.zeros((Nsample*28,Nsample*28))\n",
    "count=0\n",
    "for i in range(Nsample):\n",
    "    for j in range(Nsample):        \n",
    "        imgRandom[i*28:(i+1)*28,j*28:(j+1)*28]=randomdecodeimg[count,...]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.imshow(imgRandom,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
