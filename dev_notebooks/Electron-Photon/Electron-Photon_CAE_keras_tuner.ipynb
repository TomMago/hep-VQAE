{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9080d094-8323-45f5-a578-aeed60dc8ab0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Electron Photon tagging\n",
    "\n",
    "This is a first test to implement a QAE. \n",
    "The task is to identify Electrons and Photons from em-calorimeter images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebb528-e2a8-4c93-8fb6-e1ecb32a74b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b53f85c-d0fb-489d-b816-6ed710eeda35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 19:22:42.174773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-03 19:22:42.174791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/tom/.conda/envs/tfq/lib/python3.9/site-packages/cirq/ops/gateset.py:376: UserWarning: v0.14.1 is the last release `cirq.GlobalPhaseGate` is included by default. If you were relying on this behavior, you can include a `cirq.GlobalPhaseGate` in your `*gates`. If not, then you can ignore this warning. It will be removed in v0.16\n",
      "  warnings.warn(\n",
      "2022-08-03 19:22:43.994621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-03 19:22:43.994646: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-03 19:22:43.994666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-08-03 19:22:43.995332: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "from hep_VQAE import data_preprocessing as dp\n",
    "from hep_VQAE import CAE as cae\n",
    "from tensorflow.keras import layers, losses\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e698f52-4504-4e17-92ed-29c79452b31a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79ad71b-abd8-4e82-8d07-5a10d2839544",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"../../data/electron.hdf5\",\"r\")\n",
    "f2 = h5py.File(\"../../data/photon.hdf5\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9294cf5d-295c-4ec5-afbe-37534659fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrons = f.get('X')[:,:,:,0]\n",
    "photons = f2.get('X')[:,:,:,0]\n",
    "electrons_y = f.get('y')[:]\n",
    "photons_y = f2.get('y')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a102627-f5f1-45a2-a347-b86636a9825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(np.vstack((electrons,photons)),\n",
    "                                                    np.transpose(np.hstack((electrons_y, photons_y))),\n",
    "                                                    test_size=0.2, shuffle=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train,\n",
    "                                                    test_size=0.4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16099271-c963-402c-86e9-f467d540e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_electrons = x_train[y_train==1]\n",
    "x_train = x_train[y_train==0]\n",
    "\n",
    "x_val_electrons = x_val[y_val==1]\n",
    "x_val = x_val[y_val==0]\n",
    "\n",
    "x_test_electrons = x_test[y_test==1]\n",
    "x_test = x_test[y_test==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d5d274-0549-4b9b-89ce-30baece5ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_train_electrons = x_train_electrons.reshape(x_train_electrons.shape + (1,))\n",
    "\n",
    "x_val = x_val.reshape(x_val.shape + (1,))\n",
    "x_val_electrons = x_val_electrons.reshape(x_val_electrons.shape + (1,))\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "x_test_electrons = x_test_electrons.reshape(x_test_electrons.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5004350f-30fe-40b0-8ad7-e59757b9187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = np.max(x_train)\n",
    "x_train = x_train / max_norm\n",
    "x_train_electrons = x_train_electrons / max_norm\n",
    "\n",
    "x_val = x_val / max_norm\n",
    "x_val_electrons = x_val_electrons / max_norm\n",
    "\n",
    "x_test = x_test / max_norm\n",
    "x_test_electrons = x_test_electrons / max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030641a-ac37-4fcf-8862-18354e332a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6495b507-bbc0-4795-8cb6-3eb11819b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution() \n",
    "from hep_VQAE import utils as ut\n",
    "def emd(y_true, y_pred):\n",
    "    avg_emd = ut.avg_emd(y_true.numpy(), y_pred.numpy())\n",
    "    return avg_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87952b5d-bba5-4470-b7ad-20a3f8f22371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    latent_dim = hp.Int(\"latent_dim\", min_value=40, max_value=200, step=20)\n",
    "    fkc = hp.Choice('filters-kernels-choice',[0,1,2,3])\n",
    "    if fkc == 0:\n",
    "        filters, kernels = ([[8],[16],[32],[64]],[[],[],[],[]])\n",
    "    elif fkc == 1:\n",
    "        filters, kernels = ([[8,8],[16,16],[32],[64]],[[4],[4],[],[]])\n",
    "    elif fkc == 2:\n",
    "        filters, kernels = ([[16],[32],[64],[128]],[[],[],[],[]])\n",
    "    elif fkc == 3:\n",
    "        filters, kernels = ([[10,10,10],[10,10,10],[10,10,10],[10,10,10]],[[4,4],[4,4],[4,4,4],[2,2]])\n",
    "    ae = cae.Convolutional_Autoencoder_hp_model(latent_dim,filters,kernels)\n",
    "    lr = hp.Choice('lr', [0.01,0.001,0.0005,0.0001,0.00005])\n",
    "    #ae.add_metric(emd, name='emd', aggregation='mean')\n",
    "    ae.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr), run_eagerly=True, metrics=[emd])\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "085ad1d3-a2bf-4ea9-bf72-91b78af245f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=keras_tuner.Objective(\"val_emd\", direction=\"min\"),\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"gammaetune\",\n",
    "    project_name=\"first_tune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b64abef-e586-4e83-8065-4df229e42c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "latent_dim (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 40, 'max_value': 200, 'step': 20, 'sampling': None}\n",
      "filters-kernels-choice (Choice)\n",
      "{'default': 0, 'conditions': [], 'values': [0, 1, 2, 3], 'ordered': True}\n",
      "lr (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0005, 0.0001, 5e-05], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbcab04b-74b1-438e-a067-822b58873252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "120               |120               |latent_dim\n",
      "2                 |0                 |filters-kernels-choice\n",
      "0.0001            |0.01              |lr\n",
      "\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 33s 15s/step - loss: 0.6907 - emd: 510.0371 - val_loss: 0.6887 - val_emd: 508.9910\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6875 - emd: 508.3708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x_train, x_train, epochs=5, steps_per_epoch=3, shuffle=True, batch_size=256, validation_data=(x_val[:5000], x_val[:5000]), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b0c4e-a42b-4757-b31b-8789b3d3d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ad66d-548c-47fc-b4af-7daf4257a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 28, 28))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483243f-4fa3-43bb-a92b-a26a903ba980",
   "metadata": {
    "tags": []
   },
   "source": [
    "# old emd metric stuff"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1aeea653-9d7f-4794-b740-c8f9d8426e70",
   "metadata": {},
   "source": [
    "import tensorflow.keras as keras\n",
    "from hep_VQAE import utils as ut\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data=(), logs={}):\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        self._data = []\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        x_val_predict = np.asarray(self.model.predict(X_val))\n",
    "        \n",
    "        avg_emd = ut.avg_emd(X_val, x_val_predict)\n",
    "\n",
    "        self._data.append({\n",
    "            'val_emd': avg_emd,\n",
    "        })\n",
    "        return\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data\n",
    "\n",
    "metrics = Metrics(validation_data=(x_val,x_val))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e751f175-7763-4761-8f92-698ec1d9a3f3",
   "metadata": {},
   "source": [
    "metrics.get_data()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c11a3ae2-0ca8-438a-a4d1-419dd8cbda3e",
   "metadata": {},
   "source": [
    "tf.compat.v1.enable_eager_execution() \n",
    "from hep_VQAE import utils as ut\n",
    "def emd(y_true, y_pred):\n",
    "    avg_emd = ut.avg_emd(y_true.numpy(), y_pred.numpy())\n",
    "    return 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
