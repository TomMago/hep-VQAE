{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6360f2-8213-40e1-afb0-896d1d49f5ed",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook can be used to produce smaller versions of the Quark Gluon Dataset.\n",
    "I used it to produce the 12x12 and 40x40 ECAL datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a6f4a-538e-4e60-ae6f-be1615586aa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78501a2e-af16-4326-8b0c-3f1ef400ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 19:31:15.860903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-23 19:31:15.860919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa4a2c-baf3-4cda-8f05-20d7d756b9b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1826c698-be86-42bd-8281-c681c569c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = h5py.File(\"../data/quark-gluon/quark-gluon_train-set_n793900.hdf5\",\"r\")\n",
    "f2 = h5py.File(\"../data/quark-gluon/quark-gluon_test-set_n139306.hdf5\",\"r\")\n",
    "f = h5py.File(\"../data/quark-gluon/quark-gluon_test-set_n10000.hdf5\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e83dc-3145-4988-8caa-ec642996c35e",
   "metadata": {},
   "source": [
    "There are three files:\n",
    "- f3: ~800000 samples\n",
    "- f2: ~140000 samples\n",
    "- f: 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b42a496-8337-47a9-8170-05d61a7b703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f3.get('X_jets')\n",
    "y_train = f3.get('y')\n",
    "\n",
    "x_val = f2.get('X_jets')\n",
    "y_val = f2.get('y')\n",
    "\n",
    "x_test = f.get('X')\n",
    "y_test = f.get('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e31572-6aa5-4f5c-944b-8a5d7c62bf98",
   "metadata": {},
   "source": [
    "We will just name the dataset to reduce as `x_red`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f855550-36e3-4313-86c9-d82be6adb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red = f.get('X')\n",
    "y_red = f.get('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed444735-75ed-4988-8735-21b9bd998130",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## resize and safe to new file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd2e60-f595-42c3-b548-8ada76373051",
   "metadata": {},
   "source": [
    "The different methods that can be used to reduce the dimension. \n",
    "Usually cropping first and then resizing should be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8521ff-e401-459d-8f20-9800423e9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(x, channel, crop_fraction):\n",
    "    return tf.image.central_crop(x[:,:,:,channel].reshape(x.shape[0],125,125,1), crop_fraction)\n",
    "\n",
    "def simple_resize(x, channel, scale, meth=\"bilinear\"):\n",
    "    return tf.image.resize(x[:,:,:,channel].reshape((x.shape[0],125,125,1)), (scale,scale), method=meth).numpy()\n",
    "\n",
    "def crop_and_resize(x, channel, scale, crop_fraction=0.8,meth=\"bilinear\"):\n",
    "    cropped = tf.image.central_crop(x[:,:,:,channel].reshape(x.shape[0],125,125,1), crop_fraction)\n",
    "    return tf.image.resize(cropped, (scale,scale), method=meth).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb383f7-fba7-4e6c-8a5a-721e018202fa",
   "metadata": {},
   "source": [
    "Fix some settings:\n",
    "\n",
    "- batch size: how many samples to load into memory at once\n",
    "- file name: name of output file\n",
    "- output shape: shape the rescale images should have\n",
    "- channel: which channel to use (in this case only ecal) - you could also rewrite to use all channels\n",
    "- crop fraction: To what percent to crop down before rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c092ea4-2b4e-47d3-b888-6cb40850e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "num_batches = x_red.shape[0] // batch_size\n",
    "events = num_batches * batch_size\n",
    "file_name = \"QG_rescaled\"\n",
    "channel = 1\n",
    "crop_fraction = 0.8\n",
    "\n",
    "output_shape = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8103d54f-e7dc-43bb-950d-d89e2c7138ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 19:31:17.432170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-23 19:31:17.432188: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-23 19:31:17.432203: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tomskopfbahnhof): /proc/driver/nvidia/version does not exist\n",
      "2022-09-23 19:31:17.432419: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  399 / 400\r"
     ]
    }
   ],
   "source": [
    "fnew = h5py.File(file_name, \"w\")\n",
    "\n",
    "dsetx = fnew.create_dataset(\"X\", (events,) + output_shape, dtype='f')\n",
    "dsety = fnew.create_dataset(\"y\", (events,), dtype='i')\n",
    "\n",
    "\n",
    "for i in range(int(num_batches)):\n",
    "    y = y_red[i * batch_size: (i + 1) * batch_size]\n",
    "    x = x_red[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "    x_small = crop_and_resize(x, channel, output_shape[0], crop_fraction=crop_fraction)\n",
    "    \n",
    "    div1 = np.max(x_small, axis=(1,2)).reshape((x.shape[0],1,1,1))\n",
    "    div1[div1 == 0] = 1\n",
    "    x_small = x_small / div1\n",
    "\n",
    "    dsety[i * batch_size: (i + 1) * batch_size] = y\n",
    "    dsetx[i * batch_size: (i + 1) * batch_size] = x_small.reshape((x_small.shape[0],)+output_shape)\n",
    "    print(\"batch \",i,\"/\",num_batches, end=\"\\r\")\n",
    "    \n",
    "fnew.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4dcf0d-cd6a-41d3-a0ca-3a61907c3549",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## verify scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253a3c71-7ed4-4c53-b210-6259ee3d66bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWLklEQVR4nO3df5DcdX3H8dcrd5cfl4QklxBI7oCEBlKo0wZ6gwgtOmAd/FGxHUfRisDYMq0V0TK16DhjceqMVWtxHHUaEcFCoYLMyDDUX6h1rMoYExhIIgUhgfwil0suv8iPu+TdP3ZTl8tdLvl89nY/uX0+ZjLZX+99f3Zv3/ve73e/+/k4IgQAQGkmNXsAAACMhAYFACgSDQoAUCQaFACgSDQoAECRaFAAgCLRoE5Ctu+0/U/NHgcAjCcaVKFsX237Mdt7bW+tnn6/bTd7bACOZvs62z9t9jgmEhpUgWzfLOkLkj4r6XRJp0n6a0mXSprcxKEBJ5Vq03jS9su2t9j+su1ZzR4Xjg8NqjDV4vmkpPdHxAMRsTsqVkXEX0TEgWG3P+pTm+2wveTI/dn+hu0+2+ttf9z2pNpY25+zvcP287bf2KjHCoyn6ge9f5b095JmSbpY0iJJ37PdUedc7fW8P1TQoMrzGklTJH27Tvf3RVWK82xJr5X0XknX11z/aklPS5on6TOSvsZuRJzsbJ8i6VZJN0bEdyJiMCLWSXqHKrXw7uHf5dp+ne0NNedvsf0b27ttr7H9ZzXXXWf7f2z/q+1+Sf84whg+W/0AyBZbIhpUeeZJ2hYRQ0cusP0z2wO299m+7HjvyHabpKslfbS6JbZO0r9IuqbmZusj4qsRcUjSXZIWqLJLETiZXSJpqqQHay+MiD2SHpH0huO4j99I+mNVPuDdKulu2wtqrn+1pOdUqZdPHbnQ9iTbX5X0+5LeEBE7Mx5HS6NBladf0rzaXQYRcUlEzK5edyJ/s3mSOiStr7lsvaTumvNbavK8XD054wTHDJTmqA96NTZLOnWsO4iI+yNiU0Qcjoj/lPSMpItqbrIpIr4YEUMRsa96WYekeyV1SfrTmppCAhpUeX4u6YCkq47z9nsldR45Y/v0muu2SRqUdFbNZWdK2pg5RqB02zTsg16NBdXrj8n2e20/Xt17MSDpVao0viNeHCFsiSq1e2tEHDzxYaMWDaowETGgyu6EL9t+u+2Z1V0GyyRNHyHkCUm/Z3uZ7amq2Rde3W33TUmfqt7PWZL+TtLd4/wwgGY78kHvz2svtD1D0hsl/VjDPtypcsTskdudJemrkj4gaW51D8ZTkmq/nx1praK1qnzH+1+2l+Y+iFZHgypQRHxGlUbyEUkvVf/9m6R/kPSzYbf9X1WO+vuBKrsghv8O40ZVCvG56nX/IemOcRw+0HTV731ulfRF21fa7rC9SJUPbNsk3SPpcUlvst1V3fPwoZq7mK5KA+qTJNvXq7IFdTy575X0MUk/sP07dXlALcosWAhgorL9PkkfVmXX2xRJ/y3p3RGxqbrH4S5VtqjWSfq6pJsjoqca+ylJfyPpsKRvSPpDSf8eEbfbvk7SX0bEH9XkesVltv9K0sclvbZ6gBJOEA0KQEuobgV9UtKlEfFCs8eDsdGgALQM29dIGoyI+5o9FoyNBgUAKBIHSQAAikSDAgAUqaETHHZ1dUVPT09S7KFDh5LztrW1NSX24MH03+nl7HrN3W3b3p7+spg0qTmfeXJeH6nP16ZNm7Rjx46Gz1s4Z86c6O7uHvuGI8iZZrGjI31+1X379o19o1HkjDnntZxbR4ODg8mxOe87OTWY83zl1OCTTz65LSKOmt2joQ2qp6dHDz/8cFLszp3p01nNmTMnOfaUU05Jjl2/fv3YNxpFzh/7wIEDY9/oGLq6upJjZ86cmRyb80bU39+fHHv48OGkuHe+853JOXN0d3fr/vvvT4qdPDl9tZYFCxaMfaNRrF69Ojk2pzHm1H7q6+KIzZs3J8fOmJE+29i0adOSY+fPn58cOzAwkBy7aNGiEd8s2cUHACgSDQoAUKSsBlWdQuRp28/avqVegwJaDbUEHC25QVXXGvqSKtOEnC/pXbbPr9fAgFZBLQEjy9mCukjSsxHxXHVa+ft0/EtEAPgtagkYQU6D6tYr10PZoFcuhCdJsn2D7RW2V2zfvj0jHTBhjVlL1BFa0bgfJBERyyOiNyJ6cw5fBloZdYRWlNOgNko6o+Z8j1ipFUhBLQEjyGlQv5R0ju3FtidLulrSQ/UZFtBSqCVgBMkzSUTEkO0PSPqupDZJd0RE+s/FgRZFLQEjy5rqKCIekfRIncYCtCxqCTgaM0kAAIrU0Mli29rakicTHRoaSs6bM7tvziSkORO+Tp8+PTk2Z9JVSdqyZUtybM5kpDnP19y5c5NjUyf1bNZin7aTn+eciYRzJj9dunRpcuy6deuSYzs7O5Njc2pQkhYuXJgcm/Paypm09aWXXkqOPf3005NjR8MWFACgSDQoAECRaFAAgCLRoAAARaJBAQCKRIMCABSJBgUAKBINCgBQJBoUAKBINCgAQJFoUACAItGgAABFokEBAIpEgwIAFKmhy20MDg4mT9mfs9zGjh07kmNzpq7fs2dPcuyuXbuSY3OXCZg1a1Zy7MaNG5NjTznllOTYnOUJpkyZkhSXs4xLs+SMedq0acmxu3fvTo7NWeZj/fr1ybGHDx9OjpXy3rMWL16cHNvV1ZUcm2Pnzp11v8+Tr8IAAC2BBgUAKBINCgBQJBoUAKBIyQ3K9hm2f2R7je3Vtm+q58CAVkEtASPLOYpvSNLNEbHS9kxJv7L9/YhYU6exAa2CWgJGkLwFFRGbI2Jl9fRuSWsldddrYECroJaAkdXlOyjbiyRdIOmxEa67wfYK2yu2b99ej3TAhDVaLVFHaEXZDcr2DEnfkvShiDjq16URsTwieiOit1k/IANOBseqJeoIrSirQdnuUKWg7omIB+szJKD1UEvA0XKO4rOkr0laGxGfr9+QgNZCLQEjy9mCulTSNZIut/149d+b6jQuoJVQS8AIkg8zj4ifSnIdxwK0JGoJGBkzSQAAitTQ5TYmTZqkzs7OpNht27Yl5x0cHEyOzVky4/nnn0+ObW9P/9PkLDGQm3vJkiXJsQcOHEiOXbhwYXLseeedlxQ3derU5Jw5bKujoyMpdsaMGcl516xJ/91wzt/24MGDybF9fX3JsTlLuEh5dbRp06bk2NT3WEnJrytJmjx5cnLsaNiCAgAUiQYFACgSDQoAUCQaFACgSDQoAECRaFAAgCLRoAAARaJBAQCKRIMCABSJBgUAKBINCgBQJBoUAKBINCgAQJFoUACAIjV0uY3Dhw/r5ZdfTordtWtXct5169Ylx27YsKEpeXfu3JkcO2lS3ueOrq6u5NicZRXOPPPM5NiBgYHk2L179ybFpb6Wcw0ODmrz5s1JsZXV5dNs2bIlOba/vz859tlnn02O3b17d3Js7nIb06dPT44999xzk2NzlieZP39+cmzOUi6jYQsKAFAkGhQAoEg0KABAkWhQAIAiZTco2222V9l+uB4DAloVtQS8Uj22oG6StLYO9wO0OmoJqJHVoGz3SHqzpNvrMxygNVFLwNFyt6Buk/QRSYdHu4HtG2yvsL1i+/btmemACes2HaOWauso5zdfwMkkuUHZfoukrRHxq2PdLiKWR0RvRPTm/AAUmKiOp5Zq62j27NmNGxzQRDlbUJdKeqvtdZLuk3S57bvrMiqgtVBLwAiSG1REfDQieiJikaSrJf0wIt5Tt5EBLYJaAkbG76AAAEWqy2SxEfFjST+ux30BrYxaAn6LLSgAQJEavtxG6lTwOcs45BzenrqsgSStXLkyOXb16tXJsYcPj3rU/3E555xzkmMvu+yy5NiOjo7k2Jwj23KXJ2m09vZ2zZs3Lym2r68vOe/Q0FBybM6h8U888URy7C9+8Yvk2Nw6uuiii5Jjc454njNnTnJse3t6S0h9TR7LyVWZAICWQYMCABSJBgUAKBINCgBQJBoUAKBINCgAQJFoUACAItGgAABFokEBAIpEgwIAFIkGBQAoEg0KAFAkGhQAoEg0KABAkRq63MahQ4fU39+fFDt16tSsvKlSlweR8pYnyJG7TECOnMecs+zFlClTkmP379+fFBcRyTlztLW1adasWUmxOcvH2E6OzVkuJ0dO3mb9fSVpcHAwOTbnMee8z86fPz85djRsQQEAikSDAgAUiQYFACgSDQoAUKSsBmV7tu0HbP/a9lrbr6nXwIBWQi0BR8s9iu8Lkr4TEW+3PVlSZx3GBLQiagkYJrlB2Z4l6TJJ10lSRByUlH5MNtCiqCVgZDm7+BZL6pP0ddurbN9ue/rwG9m+wfYK2ysGBgYy0gET1pi1VFtHqb8lBE42OQ2qXdKFkr4SERdI2ivpluE3iojlEdEbEb2zZ8/OSAdMWGPWUm0dzZ07txljBBoup0FtkLQhIh6rnn9AlSIDcGKoJWAEyQ0qIrZIetH20upFV0haU5dRAS2EWgJGlnsU342S7qkedfScpOvzhwS0JGoJGCarQUXE45J66zMUoHVRS8DRmEkCAFAkGhQAoEgNXw9qz549SbEzZsxIzptzWO6ZZ56ZHJuznszSpUvHvtEocteDylkT5uyzz06OnTNnTnJszmOeNm1aUlzO+lU5BgcHtWXLlqTYZq2r1tXVlRzb25u+5zPn9djenvf22NHRkRx76qmnJsemrhUmSZs2bUqOzVkvbDRsQQEAikSDAgAUiQYFACgSDQoAUCQaFACgSDQoAECRaFAAgCLRoAAARaJBAQCKRIMCABSJBgUAKBINCgBQJBoUAKBINCgAQJEautxGZ2enli1blhS7d+/e5LwHDhxIjp0yZUpybM4SITlypvmXpP379yfH5kz1v2TJkuTYBQsWJMeee+65SXE5S1fk6Ojo0GmnnZYUe/DgweS8OTV4xhlnJMfOnj07ObazszM5Nud9Q8p7vnKW20h9bUh5ywulLltzLGxBAQCKRIMCABSJBgUAKFJWg7L9YdurbT9l+17bzdkpD5zkqCXgaMkNyna3pA9K6o2IV0lqk3R1vQYGtApqCRhZ7i6+dknTbLdL6pS0KX9IQEuiloBhkhtURGyU9DlJL0jaLGlnRHxv+O1s32B7he0V27dvTx8pMEEdTy3V1lF/f38zhgk0XM4uvjmSrpK0WNJCSdNtv2f47SJieUT0RkRvV1dX+kiBCep4aqm2jubOnduMYQINl7OL7/WSno+IvogYlPSgpEvqMyygpVBLwAhyGtQLki623Wnbkq6QtLY+wwJaCrUEjCDnO6jHJD0gaaWkJ6v3tbxO4wJaBrUEjCxrLr6I+ISkT9RpLEDLopaAozGTBACgSDQoAECRGrrcRkQkT/c/efLk5LwXXnhhcuyqVauSYyMiOXbSpPTPDm1tbcmxkjRz5szk2O7u7uTYwcHB5NicJUY2btyYFJcz3hyHDh3Srl27kmJz6ujiiy9Ojn366aeTYw8dOpQcm/M3ylmqQ8qrhZxlL3KW28j5rer8+fOTY0fDFhQAoEg0KABAkWhQAIAi0aAAAEWiQQEAikSDAgAUiQYFACgSDQoAUCQaFACgSDQoAECRaFAAgCLRoAAARaJBAQCKRIMCABSpocttDA0NJU/n3tPTk5w3Zwr58847Lzk2Z9mKWbNmJcfmLE+QGz9lypTk2JxlAvbs2ZMcazs5thkmTZqk6dOnJ8Xu3bs3Oe/+/fuTY3PqaNq0acmxqc+TJPX19SXHSnlLZuQsi7Jt27bk2KlTpybHrl+/Pjl2NGxBAQCKRIMCABSJBgUAKNKYDcr2Hba32n6q5rIu29+3/Uz1/znjO0zg5EctASfmeLag7pR05bDLbpH0aEScI+nR6nkAx3anqCXguI3ZoCLiJ5KGHwZ3laS7qqfvkvS2+g4LmHioJeDEpH4HdVpEbK6e3iJp1OODbd9ge4XtFQMDA4npgAnruGqpto76+/sbNzqgibIPkoiIkBTHuH55RPRGRO/s2bNz0wET1rFqqbaO5s6d2+CRAc2R2qBesr1Akqr/b63fkICWQi0Bo0htUA9JurZ6+lpJ367PcICWQy0Boziew8zvlfRzSUttb7D9PkmflvQntp+R9PrqeQDHQC0BJ2bMufgi4l2jXHVFnccCTGjUEnBimEkCAFAkGhQAoEgNXW7Dttrb01LmHKK+c+fO5Nic6efb2tqSY3OWvBgaGkqOlfIec07s1q3pB7B1dXUlxx48eDAprnJUeONFRPLSFznLOOQsp5Dzes752+7bty85tqOjIzlWktauXZscu2zZsuTYAwcOJMfu2LEjOXZwcDA5djRsQQEAikSDAgAUiQYFACgSDQoAUCQaFACgSDQoAECRaFAAgCLRoAAARaJBAQCKRIMCABSJBgUAKBINCgBQJBoUAKBINCgAQJHcyCUDbPdJGm3O/nmStjVsMOQlb76zIuLUcbrvUY1RR9LEfK7JO7HzjlhLDW1Qx2J7RUT0kpe8EyFvM7Xac03eiZuXXXwAgCLRoAAARSqpQS0nL3knUN5marXnmrwTNG8x30EBAFCrpC0oAAD+XxENyvaVtp+2/aztWxqU8wzbP7K9xvZq2zc1Im9N/jbbq2w/3MCcs20/YPvXttfafk2D8n64+hw/Zfte21PHKc8dtrfafqrmsi7b37f9TPX/OeORuwTNqKNq3qbVUjPqqJqXWmpALTW9Qdluk/QlSW+UdL6kd9k+vwGphyTdHBHnS7pY0t82KO8RN0la28B8kvQFSd+JiN+V9AeNyG+7W9IHJfVGxKsktUm6epzS3SnpymGX3SLp0Yg4R9Kj1fMTThPrSGpuLTWjjiRqqSG11PQGJekiSc9GxHMRcVDSfZKuGu+kEbE5IlZWT+9W5QXWPd55Jcl2j6Q3S7q9EfmqOWdJukzS1yQpIg5GxECD0rdLmma7XVKnpE3jkSQifiJp+7CLr5J0V/X0XZLeNh65C9CUOpKaV0vNqKNqXmqpQbVUQoPqlvRizfkNalCjOML2IkkXSHqsQSlvk/QRSYcblE+SFkvqk/T16i6R221PH++kEbFR0uckvSBps6SdEfG98c5b47SI2Fw9vUXSaQ3M3UhNryOp4bV0mxpfRxK1JDWolkpoUE1le4akb0n6UETsakC+t0jaGhG/Gu9cw7RLulDSVyLiAkl71YBN9Op+6qtUKeqFkqbbfs945x1JVA5Z5bDVcdLIWmpiHUnUUsNqqYQGtVHSGTXne6qXjTvbHaoU1D0R8WAjckq6VNJbba9TZTfM5bbvbkDeDZI2RMSRT7YPqFJk4+31kp6PiL6IGJT0oKRLGpD3iJdsL5Ck6v9bG5i7kZpWR1JTaqlZdSRRSw2rpRIa1C8lnWN7se3Jqnzp99B4J7VtVfYhr42Iz493viMi4qMR0RMRi1R5rD+MiHH/FBQRWyS9aHtp9aIrJK0Z77yq7I642HZn9Tm/Qo39UvshSddWT18r6dsNzN1ITakjqTm11Kw6quamlhpUS+3jnWAsETFk+wOSvqvKUSl3RMTqBqS+VNI1kp60/Xj1so9FxCMNyN0sN0q6p/oG9pyk68c7YUQ8ZvsBSStVOdprlcbpF+m275X0OknzbG+Q9AlJn5b0TdvvU2UG8HeMR+5ma2IdSdQStTROmEkCAFCkEnbxAQBwFBoUAKBINCgAQJFoUACAItGgAABFokEBAIpEgwIAFIkGBQAo0v8B3jrd4fnHIysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = h5py.File(file_name,\"r\")\n",
    "\n",
    "x_s = test.get('X')\n",
    "y_s = test.get('y')\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].imshow(np.average(x_s[y_s[:]==0],0),norm=LogNorm(), cmap='binary')\n",
    "axs[0].title.set_text('Gluon')\n",
    "\n",
    "axs[1].imshow(np.average(x_s[y_s[:]==1],0),norm=LogNorm(), cmap='binary')\n",
    "axs[1].title.set_text('Quark')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfq",
   "language": "python",
   "name": "tfq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
